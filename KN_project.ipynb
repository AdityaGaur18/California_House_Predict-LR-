{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOGYsiulbOIe8HgmWV2EGtx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Linear Regression, Ridge and Lasso"],"metadata":{"id":"P6KpSA7mrDT9"}},{"cell_type":"code","source":["!pip install scikit-learn"],"metadata":{"id":"IKGY5AWvrZFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JRNVqUefqrIW"},"outputs":[],"source":["# house price prediction\n","\n","from sklearn.datasets import fetch_california_housing\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","%matplotlib inline\n","\n"]},{"cell_type":"code","source":["df = fetch_california_housing ()"],"metadata":{"id":"h6nuPRnUrCEi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(df)"],"metadata":{"id":"NGyxEnYWsL53"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"4_ZKxkXJsWHN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["a = pd.DataFrame(df.data)\n","a.head()\n"],"metadata":{"id":"gbblyZBgsZRn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1 = pd.DataFrame(df.data)\n","df1.columns = df.feature_names\n","df1.head()"],"metadata":{"id":"MGLOo01DsxPU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1['Price']=df.target"],"metadata":{"id":"aRLxWF8Zs5Tt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.head()"],"metadata":{"id":"EMLccSETtzvn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df1.shape"],"metadata":{"id":"IPI5Wxwit32r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Divivng dataset into dependent and independent features\n","\n","  # iloc stands for integer location\n","X = df1.iloc[:,:-1]  #Excluding the last feature which is dependent(i\n","y = df1.iloc[:,-1]  #dependent features"],"metadata":{"id":"9Nuo496HuUdZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# train_X = X[:100]\n","# train_y = y[:100]\n"],"metadata":{"id":"djYuFA01yNeS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# test_X = X[100:]\n","# test_y = y[100:]\n"],"metadata":{"id":"ClmgutMQyPpd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Training and Testing the MODEL"],"metadata":{"id":"wzbB5HMV-nKl"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.37,random_state=42)\n","\n","#test_size means percentage\n","#random_state=42 --> give you the same train test split each time u run the model"],"metadata":{"id":"mNeAIQcm8sD2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Linear Regression"],"metadata":{"id":"VOPA35TV-sY2"}},{"cell_type":"code","source":[" #Linear Regression\n","\n","from sklearn.linear_model import LinearRegression\n","LR = LinearRegression()\n","# LR.fit(train_X,train_y)\n","from sklearn.model_selection import cross_val_score #making multiple combination of train and test data and also used to prevent over and underfitting\n","mse = cross_val_score(LR,X_train,y_train,scoring='neg_mean_squared_error',cv=5) #mean square error --> (1/n) * Σ(yᵢ - ŷᵢ)²\n","mean_mse = np.mean(mse)\n","print(mean_mse)\n","print(mse)"],"metadata":{"id":"GkY7vlfUvSJ8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(LinearRegression().fit(X_train,y_train).score(X_test,y_test))"],"metadata":{"id":"ccRNQwWg8-rB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Ridge Regression"],"metadata":{"id":"qbCsis0n-vpm"}},{"cell_type":"code","source":["#Ridge Regression\n","\n","from sklearn.linear_model import Ridge #ridge is used when suffer from multicollinearity\n","from sklearn.model_selection import GridSearchCV  #finding the optimal parameter values for the given set of parameters in grid\n","ridge = Ridge()\n","\n","params = {'alpha':[1e-10,1e-8,1e-5,1e-2,1,4,6,7,22,32,45,54,59,67,75,82,88,91,100,150,200,250,350,500,700,860,1000]}\n","ridge_regressor = GridSearchCV(ridge,params,scoring='neg_mean_squared_error',cv=10)\n","ridge_regressor.fit(X,y)\n"],"metadata":{"id":"xTgTZo_jxj17"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(ridge_regressor.best_params_)\n","print(ridge_regressor.best_score_)\n","\n","# mse closer to 0 and R^2 closer to 1 considered to be a good model"],"metadata":{"id":"Ma-Vca443E1g"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Lasso Regression"],"metadata":{"id":"WukeQPlb-ysE"}},{"cell_type":"code","source":["#Lasso Regression\n","\n","from sklearn.linear_model import Lasso #is a LR model which uses L1 regularization to perform both selection variable and regularization\n","from sklearn.model_selection import GridSearchCV  #finding the optimal parameter values for the given set of parameters in grid\n","lasso = Lasso()\n","\n","params = {'alpha':[1e-10,1e-8,1e-5,1e-2,1,4,6,7,22,32,45,54,59,67,75,82,88,91,100,150,200,250,350,500,700,882,88,91,100]}\n","lasso_regressor = GridSearchCV(lasso,params,scoring='neg_mean_squared_error',cv=5)\n","lasso_regressor.fit(X_test,y_test)\n"],"metadata":{"id":"_2--SIj06MEA"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(lasso_regressor.best_params_)\n","print(lasso_regressor.best_score_)"],"metadata":{"id":"Rv3cALlA63Gd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_predict = lasso_regressor.best_estimator_.predict(X_test)\n","from sklearn.metrics import r2_score\n","rs = r2_score(y_test,y_predict)"],"metadata":{"collapsed":true,"id":"ZOKdyEOI9kR8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(rs)"],"metadata":{"id":"pyg1--h1-IL7"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Logistic Regression"],"metadata":{"id":"x24TNpFc-2D9"}},{"cell_type":"code","source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.linear_model import LogisticRegression"],"metadata":{"id":"urzfAO20-32W"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = load_breast_cancer()\n","X = pd.DataFrame(df['data'],columns=df['feature_names'])  #independent feature\n"],"metadata":{"id":"n44aTtVc_BRk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X.head()"],"metadata":{"id":"iN4mO83-_prV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Dependent Feature\n","y = pd.DataFrame(df['target'],columns=['Target'])\n","y.head()"],"metadata":{"id":"2jzayzm1AC5B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y['Target'].value_counts() #check balanced or imbalance dataset"],"metadata":{"id":"NQtVaHQ-BmCy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Train Test Split\n","\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.34,random_state=42)\n"],"metadata":{"id":"lZgcGrdFCdHd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = [{'C':[1,5,10]},{'max_iter':[100,150]}]\n","\n","# C --> inverse of regularisation(1/lambda)\n","# max_iter --> maximum number of iteration for an optimization algorithm"],"metadata":{"id":"81PEuLMFDP8f"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model1 = LogisticRegression(C=100,max_iter=100)"],"metadata":{"id":"WqPSMeK7D45t"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model = GridSearchCV(model1,params,scoring='f1',cv=5)"],"metadata":{"id":"61Pvhi7YEFc1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.fit(X_test,y_test)"],"metadata":{"id":"HW3kSG1FEUNw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# finding the best params score\n","\n","model.best_score_\n","# model.best_params_"],"metadata":{"id":"O8YRZ8kyEilc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["yp = model.predict(X_test)\n","print(yp)"],"metadata":{"id":"Q43KsVfkFWNk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n"],"metadata":{"id":"qP9id-LPFaLr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["confusion_matrix(y_test,yp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icR-QAj5FpSM","executionInfo":{"status":"ok","timestamp":1754160121898,"user_tz":-330,"elapsed":15,"user":{"displayName":"Beingadi Gaur","userId":"12008523081013236105"}},"outputId":"28358d43-add7-4af2-fd39-3f726309c8f8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[ 68,   1],\n","       [  0, 125]])"]},"metadata":{},"execution_count":212}]},{"cell_type":"code","source":["accuracy_score(y_test,yp)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gZkWcU-rF2jl","executionInfo":{"status":"ok","timestamp":1754160139528,"user_tz":-330,"elapsed":73,"user":{"displayName":"Beingadi Gaur","userId":"12008523081013236105"}},"outputId":"90731b0c-1ef5-423a-8895-17b8a44a6c91"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.9948453608247423"]},"metadata":{},"execution_count":213}]},{"cell_type":"code","source":["print(classification_report(y_test,yp))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lTo0YNIbF6Bo","executionInfo":{"status":"ok","timestamp":1754160157357,"user_tz":-330,"elapsed":59,"user":{"displayName":"Beingadi Gaur","userId":"12008523081013236105"}},"outputId":"75c83ee3-1f99-47ef-9e85-fdd09d025cd7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99        69\n","           1       0.99      1.00      1.00       125\n","\n","    accuracy                           0.99       194\n","   macro avg       1.00      0.99      0.99       194\n","weighted avg       0.99      0.99      0.99       194\n","\n"]}]}]}